{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of Homework 6 is to get acquinted with the concept of Permutation-based Variable Importance. It is a global explanation method that aims at explaining the influence of a particular variable by evaluating the model of interest when it gets randomly permuted.\n",
    "\n",
    "To follow up on previous conclusions, we will reuse the models and dataset from Homework 5. That is, the baseline tree-based model will be the random forest model with other models being: multilayer perceptron, logistic regression and a simple decision tree with limited depth. We will use the *churn* dataset in which the task is to predict whether a particular client of a telephone company churned or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with training a random forest (RF) model on a single train/test split with a 4:1 ratio. We evaluate all models using ROC AUC and PR AUC to take into account the class imbalance and aggregate the performance over different thresholds. The RF model achieves a 0.7 ROC AUC and around 0.4 PR AUC. These values indicate that, in general, it is a challenging predictive task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n",
      "roc_auc: 0.709708604965522\n",
      "pr_auc: 0.3987325603160147\n"
     ]
    }
   ],
   "source": [
    "subtask_zero('random_forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with calculating PVIs for the RF model. To properly address the problem of class imbalance, we will calculate PVIs using PR AUC as the score function. Baseline (no permutations) performance is, as indicated previously, at around 0.4. Next rows indicate, for each feature, the mean and standard deviation (over 10 iterations) of the difference in performance between the baseline and the model evaluated when the given feature is permuted. Clearly, the RF model makes great use of the *total_day_minutes* variable which is in line with the findings from previous homeworks. Very close to that is the *total_day_charge* feature. These two variables are the most important for the model, and other features seem to  negligibly influence the performance when permuted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PVI for random_forest\n",
      "\n",
      "baseline: 0.399\n",
      "\n",
      "total_day_minutes: 0.110 +/- 0.016\n",
      "total_day_charge: 0.108 +/- 0.018\n",
      "total_eve_minutes: 0.036 +/- 0.015\n",
      "total_eve_charge: 0.030 +/- 0.010\n",
      "total_night_charge: 0.010 +/- 0.013\n",
      "total_night_minutes: 0.003 +/- 0.010\n",
      "total_intl_minutes: 0.002 +/- 0.007\n",
      "total_intl_charge: -0.003 +/- 0.006\n"
     ]
    }
   ],
   "source": [
    "subtask_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train additional models: a simple decision tree with maximum depth of 6 (DT), a multilayer perceptron (MLP) and logistic regression (LR). Below, their respective performance measures are included. Interestingly, MLP performs on-par or even slightly better than the RF model, LR achieves the lowest ROC AUC with a competitive PR AUC, while DT achieves the highest ROC AUC but does not handle the imbalance issue well and scores the lowest in terms of PR AUC.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n",
      "roc_auc: 0.709708604965522\n",
      "pr_auc: 0.3987325603160147\n",
      "\n",
      "\n",
      "decision_tree\n",
      "roc_auc: 0.7540452520689676\n",
      "pr_auc: 0.35753437522730497\n",
      "\n",
      "\n",
      "mlp\n",
      "roc_auc: 0.7151811736791975\n",
      "pr_auc: 0.4207226693592752\n",
      "\n",
      "\n",
      "logistic_regression\n",
      "roc_auc: 0.642420820286433\n",
      "pr_auc: 0.3811247088126789\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subtask_zero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PVIs for the above models show some interesting patterns. First, MLP model, which achieves the best performance, seems to be the only one that effectively makes use of more than two variables by exploiting the information from *total_day_charge*, *total_day_minutes* and *total_intl_charge*. LR and RF seem to use the same two features as the most important, but the linearity of LR is probably its main limitation. The DT model seems to focus only on the *total_day_charge*, which shows that there is great benefit coming from using multiple trees as in RF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PVI for random_forest\n",
      "\n",
      "baseline: 0.399\n",
      "\n",
      "total_day_minutes: 0.110 +/- 0.016\n",
      "total_day_charge: 0.108 +/- 0.018\n",
      "total_eve_minutes: 0.036 +/- 0.015\n",
      "total_eve_charge: 0.030 +/- 0.010\n",
      "total_night_charge: 0.010 +/- 0.013\n",
      "total_night_minutes: 0.003 +/- 0.010\n",
      "total_intl_minutes: 0.002 +/- 0.007\n",
      "total_intl_charge: -0.003 +/- 0.006\n",
      "\n",
      "PVI for decision_tree\n",
      "\n",
      "baseline: 0.358\n",
      "\n",
      "total_day_charge: 0.199 +/- 0.008\n",
      "total_eve_minutes: 0.049 +/- 0.004\n",
      "total_day_minutes: 0.028 +/- 0.002\n",
      "total_eve_charge: 0.028 +/- 0.013\n",
      "total_intl_minutes: 0.022 +/- 0.005\n",
      "total_night_charge: 0.017 +/- 0.007\n",
      "total_intl_charge: 0.009 +/- 0.003\n",
      "total_night_minutes: -0.005 +/- 0.004\n",
      "\n",
      "PVI for mlp\n",
      "\n",
      "baseline: 0.421\n",
      "\n",
      "total_day_charge: 0.250 +/- 0.015\n",
      "total_day_minutes: 0.169 +/- 0.013\n",
      "total_intl_charge: 0.136 +/- 0.012\n",
      "total_eve_minutes: 0.095 +/- 0.016\n",
      "total_night_minutes: 0.061 +/- 0.016\n",
      "total_intl_minutes: 0.058 +/- 0.015\n",
      "total_night_charge: 0.056 +/- 0.019\n",
      "total_eve_charge: 0.004 +/- 0.018\n",
      "\n",
      "PVI for logistic_regression\n",
      "\n",
      "baseline: 0.381\n",
      "\n",
      "total_day_minutes: 0.121 +/- 0.016\n",
      "total_day_charge: 0.116 +/- 0.015\n",
      "total_eve_charge: 0.019 +/- 0.009\n",
      "total_eve_minutes: 0.017 +/- 0.009\n",
      "total_intl_minutes: 0.009 +/- 0.009\n",
      "total_night_minutes: -0.002 +/- 0.005\n",
      "total_night_charge: -0.002 +/- 0.005\n",
      "total_intl_charge: -0.002 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "subtask_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finish with a comparison of three different methods of calculating feature importance in a tree-based model: PVI, scikit-learn's *feature_importance_* attribute of RF that measures the importance in terms of the accumulation of the impurity decrease within each tree, and the TreeSHAP algorithm from the *shap* package. We include the results below. Interestingly, while the values provided by the methods are not strictly comparable, we can compare the provided rankings of features. These match almost exactly - the only difference is with the pairs (*total_night_charge*, *total_night_minutes*), (*total_day_minutes*, *total_day_charge*) of features that are in a reverse order when using PVI or TreeSHAP. The fact that these explanations match so precisely indicates that we might be close to understanding how the model exactly works, and that the limitations of each method might not influence the explanation at this specific instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PVI for random_forest\n",
      "\n",
      "baseline: 0.399\n",
      "\n",
      "total_day_minutes: 0.110 +/- 0.016\n",
      "total_day_charge: 0.108 +/- 0.018\n",
      "total_eve_minutes: 0.036 +/- 0.015\n",
      "total_eve_charge: 0.030 +/- 0.010\n",
      "total_night_charge: 0.010 +/- 0.013\n",
      "total_night_minutes: 0.003 +/- 0.010\n",
      "total_intl_minutes: 0.002 +/- 0.007\n",
      "total_intl_charge: -0.003 +/- 0.006\n",
      "\n",
      "scikit-learn feature_importance_\n",
      "\n",
      "total_day_minutes: 0.199\n",
      "total_day_charge: 0.182\n",
      "total_eve_minutes: 0.125\n",
      "total_eve_charge: 0.124\n",
      "total_night_minutes: 0.107\n",
      "total_night_charge: 0.106\n",
      "total_intl_minutes: 0.078\n",
      "total_intl_charge: 0.080\n",
      "\n",
      "TreeSHAP feature importance\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 2493/2500 [00:54<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_day_minutes: 0.035\n",
      "total_day_charge: 0.036\n",
      "total_eve_minutes: 0.022\n",
      "total_eve_charge: 0.020\n",
      "total_night_minutes: 0.013\n",
      "total_night_charge: 0.013\n",
      "total_intl_minutes: 0.013\n",
      "total_intl_charge: 0.011\n"
     ]
    }
   ],
   "source": [
    "subtask_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASET = 'churn.csv'\n",
    "DATASET = pd.read_csv(PATH_DATASET, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = {\n",
    "    'roc_auc': roc_auc_score,\n",
    "    'pr_auc': average_precision_score}\n",
    "SCORING = make_scorer(\n",
    "    average_precision_score, \n",
    "    greater_is_better = True, \n",
    "    needs_proba = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    'random_forest': RandomForestClassifier(random_state = SEED),\n",
    "    'decision_tree': DecisionTreeClassifier(random_state = SEED, max_depth = 5),\n",
    "    'mlp': Pipeline([\n",
    "        ('standard_scaler', StandardScaler()),\n",
    "        ('mlp', MLPClassifier((32, 32), 'relu', random_state = SEED, max_iter = 1000))]),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('standard_scaler', StandardScaler()),\n",
    "        ('logistic_regression', LogisticRegression(random_state = SEED))]),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split():\n",
    "    x, y = DATASET.iloc[:, :-1], DATASET.iloc[:, -1]\n",
    "    return train_test_split(x, y, random_state = SEED)\n",
    "\n",
    "def train_models():\n",
    "    x_train, x_test, y_train, y_test = get_train_test_split()\n",
    "    results = {model_name: {} for model_name in MODELS.keys()}\n",
    "    trained_models = {}\n",
    "    for model_name, model in MODELS.items():\n",
    "        model.fit(x_train, y_train)\n",
    "        trained_models[model_name] = model\n",
    "        y_pred = model.predict_proba(x_test)[:, -1]\n",
    "        for metric_name, metric in METRICS.items():\n",
    "            results[model_name][metric_name] = metric(y_test, y_pred)\n",
    "    print('Finished')\n",
    "    return trained_models, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "trained_models, test_metrics = train_models()\n",
    "x_train, x_test, y_train, y_test = get_train_test_split()\n",
    "feature_names = x_test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n",
      "roc_auc: 0.709708604965522\n",
      "pr_auc: 0.3987325603160147\n"
     ]
    }
   ],
   "source": [
    "def subtask_zero(model_name = None):\n",
    "    if model_name is None:\n",
    "        for model_name, metrics in test_metrics.items():\n",
    "            print(model_name)\n",
    "            for metric_name, metric_v in metrics.items():\n",
    "                print(f'{metric_name}: {metric_v}')\n",
    "            print('\\n')\n",
    "    else:\n",
    "        print(model_name)\n",
    "        for metric_name, metric_v in test_metrics[model_name].items():\n",
    "            print(f'{metric_name}: {metric_v}')\n",
    "\n",
    "subtask_zero('random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PVI for random_forest\n",
      "\n",
      "baseline: 0.399\n",
      "\n",
      "total_day_minutes: 0.110 +/- 0.016\n",
      "total_day_charge: 0.108 +/- 0.018\n",
      "total_eve_minutes: 0.036 +/- 0.015\n",
      "total_eve_charge: 0.030 +/- 0.010\n",
      "total_night_charge: 0.010 +/- 0.013\n",
      "total_night_minutes: 0.003 +/- 0.010\n",
      "total_intl_minutes: 0.002 +/- 0.007\n",
      "total_intl_charge: -0.003 +/- 0.006\n"
     ]
    }
   ],
   "source": [
    "def get_pvi(model_name):\n",
    "    print(f'\\nPVI for {model_name}\\n')\n",
    "    clf = trained_models[model_name]\n",
    "    pvi = permutation_importance(\n",
    "        clf, x_test, y_test, n_repeats = 10, random_state = SEED, scoring = SCORING)\n",
    "    print(f\"baseline: {test_metrics[model_name]['pr_auc']:.3f}\\n\")\n",
    "    for i in pvi.importances_mean.argsort()[::-1]:\n",
    "        print(f\"{feature_names[i]}: {pvi.importances_mean[i]:.3f} +/- {pvi.importances_std[i]:.3f}\")\n",
    "\n",
    "def subtask_one():\n",
    "    get_pvi('random_forest')\n",
    "\n",
    "subtask_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n",
      "roc_auc: 0.709708604965522\n",
      "pr_auc: 0.3987325603160147\n",
      "\n",
      "\n",
      "decision_tree\n",
      "roc_auc: 0.7540452520689676\n",
      "pr_auc: 0.35753437522730497\n",
      "\n",
      "\n",
      "mlp\n",
      "roc_auc: 0.7151811736791975\n",
      "pr_auc: 0.4207226693592752\n",
      "\n",
      "\n",
      "logistic_regression\n",
      "roc_auc: 0.642420820286433\n",
      "pr_auc: 0.3811247088126789\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def subtask_two():\n",
    "    for model_name in trained_models.keys():\n",
    "        get_pvi(model_name)\n",
    "\n",
    "subtask_zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PVI for random_forest\n",
      "\n",
      "baseline: 0.399\n",
      "\n",
      "total_day_minutes: 0.110 +/- 0.016\n",
      "total_day_charge: 0.108 +/- 0.018\n",
      "total_eve_minutes: 0.036 +/- 0.015\n",
      "total_eve_charge: 0.030 +/- 0.010\n",
      "total_night_charge: 0.010 +/- 0.013\n",
      "total_night_minutes: 0.003 +/- 0.010\n",
      "total_intl_minutes: 0.002 +/- 0.007\n",
      "total_intl_charge: -0.003 +/- 0.006\n",
      "\n",
      "PVI for decision_tree\n",
      "\n",
      "baseline: 0.358\n",
      "\n",
      "total_day_charge: 0.199 +/- 0.008\n",
      "total_eve_minutes: 0.049 +/- 0.004\n",
      "total_day_minutes: 0.028 +/- 0.002\n",
      "total_eve_charge: 0.028 +/- 0.013\n",
      "total_intl_minutes: 0.022 +/- 0.005\n",
      "total_night_charge: 0.017 +/- 0.007\n",
      "total_intl_charge: 0.009 +/- 0.003\n",
      "total_night_minutes: -0.005 +/- 0.004\n",
      "\n",
      "PVI for mlp\n",
      "\n",
      "baseline: 0.421\n",
      "\n",
      "total_day_charge: 0.250 +/- 0.015\n",
      "total_day_minutes: 0.169 +/- 0.013\n",
      "total_intl_charge: 0.136 +/- 0.012\n",
      "total_eve_minutes: 0.095 +/- 0.016\n",
      "total_night_minutes: 0.061 +/- 0.016\n",
      "total_intl_minutes: 0.058 +/- 0.015\n",
      "total_night_charge: 0.056 +/- 0.019\n",
      "total_eve_charge: 0.004 +/- 0.018\n",
      "\n",
      "PVI for logistic_regression\n",
      "\n",
      "baseline: 0.381\n",
      "\n",
      "total_day_minutes: 0.121 +/- 0.016\n",
      "total_day_charge: 0.116 +/- 0.015\n",
      "total_eve_charge: 0.019 +/- 0.009\n",
      "total_eve_minutes: 0.017 +/- 0.009\n",
      "total_intl_minutes: 0.009 +/- 0.009\n",
      "total_night_minutes: -0.002 +/- 0.005\n",
      "total_night_charge: -0.002 +/- 0.005\n",
      "total_intl_charge: -0.002 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "subtask_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PVI for random_forest\n",
      "\n",
      "baseline: 0.399\n",
      "\n",
      "total_day_minutes: 0.110 +/- 0.016\n",
      "total_day_charge: 0.108 +/- 0.018\n",
      "total_eve_minutes: 0.036 +/- 0.015\n",
      "total_eve_charge: 0.030 +/- 0.010\n",
      "total_night_charge: 0.010 +/- 0.013\n",
      "total_night_minutes: 0.003 +/- 0.010\n",
      "total_intl_minutes: 0.002 +/- 0.007\n",
      "total_intl_charge: -0.003 +/- 0.006\n",
      "\n",
      "scikit-learn feature_importance_\n",
      "\n",
      "total_day_minutes: 0.199\n",
      "total_day_charge: 0.182\n",
      "total_eve_minutes: 0.125\n",
      "total_eve_charge: 0.124\n",
      "total_night_minutes: 0.107\n",
      "total_night_charge: 0.106\n",
      "total_intl_minutes: 0.078\n",
      "total_intl_charge: 0.080\n",
      "\n",
      "TreeSHAP feature importance\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 2490/2500 [00:58<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_day_minutes: 0.035\n",
      "total_day_charge: 0.036\n",
      "total_eve_minutes: 0.022\n",
      "total_eve_charge: 0.020\n",
      "total_night_minutes: 0.013\n",
      "total_night_charge: 0.013\n",
      "total_intl_minutes: 0.013\n",
      "total_intl_charge: 0.011\n"
     ]
    }
   ],
   "source": [
    "def subtask_three():\n",
    "    subtask_one()\n",
    "\n",
    "    print('\\nscikit-learn feature_importance_\\n')\n",
    "    imps = trained_models['random_forest'].feature_importances_\n",
    "    for f_name, f_val in zip(feature_names, imps):\n",
    "        print(f'{f_name}: {f_val:.3f}')\n",
    "\n",
    "    print('\\nTreeSHAP feature importance\\n')\n",
    "    shap_vals = shap.TreeExplainer(\n",
    "        trained_models['random_forest'], \n",
    "        data = x_test, model_output = 'probability').shap_values(x_test)\n",
    "    shap_imps = np.abs(shap_vals[1]).mean(0)\n",
    "    for f_name, f_imp in zip(feature_names, shap_imps):\n",
    "        print(f'{f_name}: {f_imp:.3f}')\n",
    "\n",
    "subtask_three()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimuw_xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
